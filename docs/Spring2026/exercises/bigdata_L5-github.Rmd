---
title: "Descriptive Data"
subtitle: "COM EM757"
author: "Dr. Ayse D. Lokmanoglu"
date: 'Lecture 5, (B) Feb 18, (A) Feb 23'
output: github_document
always_allow_html: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  error = TRUE
)
```

## Lecture 5 Table of Contents

| Section | Topic |
|---------|-------|
| 1 | Introduction to Descriptive Statistics |
| 1.1 | Why Descriptive Statistics? |
| 1.2 | Types of Variables |
| 2 | Measures of Central Tendency |
| 2.1 | Mean |
| 2.2 | Median |
| 2.3 | Mode |
| 2.4 | When to Use Which? |
| 3 | Measures of Spread |
| 3.1 | Range |
| 3.2 | Variance and Standard Deviation |
| 3.3 | Interquartile Range (IQR) |
| 4 | Visualizing Distributions |
| 4.1 | Histograms |
| 4.2 | Density Plots |
| 4.3 | Boxplots |
| 4.4 | Combining Visualizations |
| 5 | Detecting Outliers |
| 5.1 | What are Outliers? |
| 5.2 | IQR Method |
| 5.3 | Z-Score Method |
| 5.4 | Visualizing Outliers |
| 6 | Grouped Summary Statistics |
| 6.1 | Using group_by() and summarize() |
| 6.2 | Multiple Summary Statistics |
| 6.3 | Visualizing Grouped Data |
| 7 | Correlation |
| 7.1 | Understanding Correlation |
| 7.2 | Calculating Correlation |
| 7.3 | Correlation Matrices |
| 7.4 | Visualizing Correlations |
| 8 | Cross-Tabulations |
| 8.1 | Creating Frequency Tables |
| 8.2 | Proportions and Percentages |
| 8.3 | Visualizing Cross-Tabulations |

------------------------------------------------------------------------

**ALWAYS** load our libraries first

```{r, eval=TRUE}
library(tidyverse)
library(dplyr)
library(ggplot2)
```

------------------------------------------------------------------------

## 1. Introduction to Descriptive Statistics

### 1.1 Why Descriptive Statistics?

Descriptive statistics help us **understand and summarize** our data before diving into more complex analyses. They answer questions like:

-   What is the typical value in my data?
-   How spread out are my values?
-   Are there any unusual observations?
-   How are my variables related?

**Descriptive vs. Inferential Statistics:**

| Descriptive | Inferential |
|-------------|-------------|
| Summarizes data | Makes predictions |
| Describes what IS | Estimates what MIGHT BE |
| No uncertainty | Includes uncertainty |
| e.g., "The mean age is 25" | e.g., "The population mean is likely between 23-27" |

------------------------------------------------------------------------

### 1.2 Types of Variables

Understanding variable types helps us choose the right statistics:

**Numeric (Quantitative):**

-   **Continuous**: Can take any value (e.g., height, weight, temperature)
-   **Discrete**: Only whole numbers (e.g., count of children, number of books)

**Categorical (Qualitative):**

-   **Nominal**: No natural order (e.g., color, gender, major)
-   **Ordinal**: Has natural order (e.g., education level, satisfaction rating)

```{r, eval=TRUE}
# Create our example dataset
student_data <- read_csv("https://raw.githubusercontent.com/aysedeniz09/IntroCSS/refs/heads/main/data/student_lifestyle_dataset.csv")

```

**Identify variable types:**

```{r, eval=TRUE}
# Check each variable
str(student_data)
```


Let's create GPA levels for some categorical data

```{r}
student_data <- student_data |> 
  mutate(
        GPA_Level = case_when(
      GPA < 2.90 ~ "LowGPA",
      GPA >= 2.90 & GPA <= 3.33 ~ "MediumGPA",
      GPA > 3.33 ~ "HighGPA"
    ))

str(student_data)

```

------------------------------------------------------------------------

## 2. Measures of Central Tendency

Central tendency tells us about the **typical** or **center** value in our data.

### 2.1 Mean

The **arithmetic mean** (average) is the sum of all values divided by the number of values.

$$\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}$$

```{r, eval=TRUE}
# Calculate mean
mean(student_data$Study_Hours_Per_Day)

# Mean with missing values
x <- c(10, 20, NA, 30, 40)
mean(x)  # Returns NA

# Remove NA values
mean(x, na.rm = TRUE)
```

------------------------------------------------------------------------

### 2.2 Median

The **median** is the middle value when data is sorted. It's more robust to outliers than the mean.

```{r, eval=TRUE}
# Calculate median
median(student_data$Study_Hours_Per_Day)

```

------------------------------------------------------------------------

### 2.3 Mode

The **mode** is the most frequently occurring value. R doesn't have a built-in mode function, so we create one:

```{r, eval=TRUE}
# Create a mode function
get_mode <- function(x) {
  unique_x <- unique(x)
  unique_x[which.max(tabulate(match(x, unique_x)))]
}

# Find mode
get_mode(student_data$Study_Hours_Per_Day)

# Mode is most useful for categorical data
get_mode(student_data$Stress_Level)
```

------------------------------------------------------------------------

### 2.4 When to Use Which?

| Measure | Best For | Sensitive to Outliers? |
|---------|----------|------------------------|
| **Mean** | Symmetric distributions, interval/ratio data | Yes |
| **Median** | Skewed distributions, ordinal data | No |
| **Mode** | Categorical data, finding most common value | No |

**TRY: Compare all three measures**

```{r, eval=TRUE}
# Summary function gives us multiple measures
summary(student_data$GPA)
```

------------------------------------------------------------------------

#### Class Exercise: Central Tendency

1. Calculate the mean, median, and mode of `GPA`.
3. Which measure would you report for wellness ratings? Why?

```{r}
### Your workspace
```

------------------------------------------------------------------------

## 3. Measures of Spread

Spread (or dispersion) tells us how **varied** or **spread out** our data is.

### 3.1 Range

The simplest measure of spread - the difference between maximum and minimum values.

```{r, eval=TRUE}
# Range
range(student_data$Study_Hours_Per_Day)

# Difference
max(student_data$Study_Hours_Per_Day) - min(student_data$Study_Hours_Per_Day)

# Or use diff()
diff(range(student_data$Study_Hours_Per_Day))
```

<mark>**Limitation:** Range is very sensitive to outliers since it only uses two values.</mark>

------------------------------------------------------------------------

### 3.2 Variance and Standard Deviation

**Variance** measures the average squared deviation from the mean:

$$s^2 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n-1}$$

**Standard Deviation** is the square root of variance (same units as the data):

$$s = \sqrt{s^2}$$

```{r, eval=TRUE}
# Variance
var(student_data$Study_Hours_Per_Day)

# Standard deviation
sd(student_data$Study_Hours_Per_Day)

# Verify: SD is square root of variance
sqrt(var(student_data$Study_Hours_Per_Day))
```

**Interpretation:** On average, study hours deviate from the mean by about `r round(sd(student_data$Study_Hours_Per_Day), 1)` hours.

------------------------------------------------------------------------

### 3.3 Interquartile Range (IQR)

The **IQR** is the range of the middle 50% of data (Q3 - Q1). It's robust to outliers.

```{r, eval=TRUE}
# Quartiles
print("Quantile: ")
quantile(student_data$Study_Hours_Per_Day)

# IQR
print("IQR: ")
IQR(student_data$Study_Hours_Per_Day)

# Verify
print("Quantile 75% - 25%: ")
quantile(student_data$Study_Hours_Per_Day, 0.75) - quantile(student_data$Study_Hours_Per_Day, 0.25)
```

**Understanding Quartiles:**

-   **Q1 (25th percentile)**: 25% of data falls below this value
-   **Q2 (50th percentile)**: The median
-   **Q3 (75th percentile)**: 75% of data falls below this value

------------------------------------------------------------------------

**Summary of Spread Measures:**

```{r, eval=TRUE}
# All spread measures together
tibble(
  Measure = c("Range", "Variance", "Std Dev", "IQR"),
  Value = c(
    diff(range(student_data$Study_Hours_Per_Day)),
    var(student_data$Study_Hours_Per_Day),
    sd(student_data$Study_Hours_Per_Day),
    IQR(student_data$Study_Hours_Per_Day)
  )
)
```

------------------------------------------------------------------------

## 4. Visualizing Distributions

### 4.1 Histograms

Histograms show the **frequency distribution** of continuous data by dividing it into bins.

```{r, eval=TRUE}
# Basic histogram
ggplot(student_data, aes(x = Study_Hours_Per_Day)) +
  geom_histogram(binwidth = 3, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of Study Hours",
    x = "Study Hours per day",
    y = "Count"
  ) +
  theme_minimal()
```

**Adjusting bin width:**

```{r, eval=TRUE}
# Different bin widths
p1 <- ggplot(student_data, aes(x = Study_Hours_Per_Day)) +
  geom_histogram(binwidth = 20, fill = "steelblue", color = "white") +
  labs(title = "Binwidth = 20") +
  theme_minimal()

p2 <- ggplot(student_data, aes(x = Study_Hours_Per_Day)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  labs(title = "Binwidth = 1") +
  theme_minimal()

# Display side by side (requires patchwork or gridExtra)
# install.packages("patchwork")
library(patchwork)
p1 + p2
```

------------------------------------------------------------------------

### 4.2 Density Plots

Density plots show a **smoothed** version of the distribution.

```{r, eval=TRUE}
# Density plot
ggplot(student_data, aes(x = Study_Hours_Per_Day)) +
  geom_density(fill = "steelblue", alpha = 0.5) +
  labs(
    title = "Density of Study Hours",
    x = "Study Hours per Day",
    y = "Density"
  ) +
  theme_minimal()
```

**Comparing groups with density:**

```{r, eval=TRUE}
# Density by major
ggplot(student_data, aes(x = Study_Hours_Per_Day, fill = Stress_Level)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Study Hours by Stress Level",
    x = "Study Hours per Day",
    y = "Density",
    fill = "Major"
  ) +
  theme_minimal()
```

------------------------------------------------------------------------

### 4.3 Boxplots

Boxplots display the **five-number summary** (min, Q1, median, Q3, max) and outliers.

```{r, eval=TRUE}
# Basic boxplot
ggplot(student_data, aes(y = Physical_Activity_Hours_Per_Day)) +
  geom_boxplot(fill = "steelblue", width = 0.3) +
  labs(
    title = "Boxplot of Study Hours",
    y = "Physical Activity Hours per day"
  ) +
  theme_minimal()
```

**Reading a boxplot:**

-   **Box**: Contains the middle 50% of data (Q1 to Q3)
-   **Line in box**: The median
-   **Whiskers**: Extend to min/max within 1.5 × IQR
-   **Points beyond whiskers**: Potential outliers

**Boxplots by group:**

```{r, eval=TRUE}
# Boxplot by major
ggplot(student_data, aes(x = Stress_Level, y = Study_Hours_Per_Day, fill = Stress_Level)) +
  geom_boxplot() +
  labs(
    title = "Study Hours by Stress Level",
    x = "Stress Level",
    y = "Study Hours per Day"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

------------------------------------------------------------------------

### 4.4 Combining Visualizations

**Histogram + Density:**

```{r, eval=TRUE}
ggplot(student_data, aes(x = Study_Hours_Per_Day)) +
  geom_histogram(aes(y = after_stat(density)), 
                 binwidth = 1, fill = "steelblue", color = "white") +
  geom_density(color = "red", linewidth = 1) +
  labs(
    title = "Study Hours: Histogram with Density Overlay",
    x = "Study Hours per Day",
    y = "Density"
  ) +
  theme_minimal()
```

**Boxplot + Points (Jitter):**

```{r, eval=TRUE}
ggplot(student_data, aes(x = Stress_Level, y = Study_Hours_Per_Day, fill = Stress_Level)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  labs(
    title = "Study Hours by Stress Level with Individual Points",
    x = "Stress Level",
    y = "Study Hours per Day"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

------------------------------------------------------------------------

#### Class Exercise: Visualizing Distributions

1. Create a histogram of `GPA` with an appropriate bin width.
2. Add an overlapping density plot of `GPA`.
3. Create a boxplot comparing `GPA` across `Stress_Level`.
4. Which stress level has the highest median GPA? Which has the most variation?

```{r}
### Your workspace
```

------------------------------------------------------------------------

## 5. Detecting Outliers

### 5.1 What are Outliers?

**Outliers** are observations that are unusually far from other values. They can be:

-   **Valid extreme values**: Legitimate data points that happen to be unusual
-   **Errors**: Data entry mistakes, measurement errors
-   **Different populations**: Data from a different group mixed in

<mark>**Important:** Don't automatically remove outliers! First investigate why they exist.</mark>

------------------------------------------------------------------------

### 5.2 IQR Method

The **IQR method** defines outliers as values beyond:

-   **Lower bound**: Q1 - 1.5 × IQR
-   **Upper bound**: Q3 + 1.5 × IQR

```{r, eval=TRUE}
# Calculate bounds
Q1 <- quantile(student_data$Physical_Activity_Hours_Per_Day, 0.25)
Q3 <- quantile(student_data$Physical_Activity_Hours_Per_Day, 0.75)
IQR_val <- IQR(student_data$Physical_Activity_Hours_Per_Day)

lower_bound <- Q1 - 1.5 * IQR_val
upper_bound <- Q3 + 1.5 * IQR_val

cat("Q1:", Q1, "\n")
cat("Q3:", Q3, "\n")
cat("IQR:", IQR_val, "\n")
cat("Lower bound:", lower_bound, "\n")
cat("Upper bound:", upper_bound, "\n")
```

```{r, eval=TRUE}
# Find outliers
outliers <- student_data |> 
  filter(Physical_Activity_Hours_Per_Day < lower_bound | Physical_Activity_Hours_Per_Day > upper_bound)

cat("Number of outliers:", nrow(outliers), "\n")
print(outliers)
```

------------------------------------------------------------------------

### 5.3 Z-Score Method

The **Z-score** measures how many standard deviations a value is from the mean:

$$z = \frac{x - \bar{x}}{s}$$

Values with |z| > 2 or |z| > 3 are often considered outliers.

```{r, eval=TRUE}
# Calculate z-scores
student_data <- student_data |> 
  mutate(
    Physical_Activity_Hours_Per_Day_z = (Physical_Activity_Hours_Per_Day - mean(Physical_Activity_Hours_Per_Day)) / sd(Physical_Activity_Hours_Per_Day)
  )

# View z-scores
student_data |> 
  select(Student_ID, Stress_Level, Physical_Activity_Hours_Per_Day, Physical_Activity_Hours_Per_Day_z) |> 
  arrange(desc(abs(Physical_Activity_Hours_Per_Day_z))) |> 
  head(10)
```

```{r, eval=TRUE}
# Find outliers using z-score > 2
z_outliers <- student_data |> 
  filter(abs(Physical_Activity_Hours_Per_Day_z) > 2)

cat("Outliers (|z| > 2):", nrow(z_outliers), "\n")
print(z_outliers |> select(Student_ID, Stress_Level, Physical_Activity_Hours_Per_Day, Physical_Activity_Hours_Per_Day_z))
```

------------------------------------------------------------------------

### 5.4 Visualizing Outliers

**Boxplot (automatically shows outliers):**

```{r, eval=TRUE}
# Boxplot shows outliers as points
ggplot(student_data, aes(x = Stress_Level, y = Physical_Activity_Hours_Per_Day, fill = Stress_Level)) +
  geom_boxplot() +
  labs(
    title = "Boxplot Showing Outliers",
    x = "Stress Level",
    y = "Physical Activity Hours"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Scatter plot with outliers highlighted:**

```{r, eval=TRUE}
# Identify outliers
student_data <- student_data |> 
  mutate(
    is_outlier = Physical_Activity_Hours_Per_Day < lower_bound | Physical_Activity_Hours_Per_Day > upper_bound
  )

ggplot(student_data, aes(x = Physical_Activity_Hours_Per_Day, y = GPA, color = is_outlier)) +
  geom_point(size = 3) +
  scale_color_manual(values = c("FALSE" = "steelblue", "TRUE" = "red"),
                     labels = c("Normal", "Outlier")) +
  labs(
    title = "Scatter Plot with Outliers Highlighted",
    x = "Physical Activity Hours",
    y = "GPA",
    color = "Status"
  ) +
  theme_minimal()
```

------------------------------------------------------------------------

#### Class Exercise: Outlier Detection

1. Calculate the IQR bounds for `GPA`.
2. Identify any outliers using the IQR method.
3. Calculate z-scores for `GPA` and find values with |z| > 2.
4. Create a visualization that highlights outliers.

```{r}
### Your workspace
```

------------------------------------------------------------------------

## 6. Grouped Summary Statistics

### 6.1 Using group_by() and summarize()

The combination of `group_by()` and `summarize()` is powerful for calculating statistics by group.

```{r, eval=TRUE}
# Mean study hours by stress level
student_data |> 
  group_by(Stress_Level) |> 
  summarize(mean_hours = mean(Study_Hours_Per_Day))
```

------------------------------------------------------------------------

### 6.2 Multiple Summary Statistics

Calculate multiple statistics at once:

```{r, eval=TRUE}
# Comprehensive summary by stress level
summary_by_stresslevel <- student_data |> 
  group_by(Stress_Level) |> 
  summarize(
    n = n(),
    mean_hours = mean(Study_Hours_Per_Day),
    median_hours = median(Study_Hours_Per_Day),
    sd_hours = sd(Study_Hours_Per_Day),
    min_hours = min(Study_Hours_Per_Day),
    max_hours = max(Study_Hours_Per_Day),
    mean_score = mean(GPA)
  )

print(summary_by_major)
```

**Group by multiple variables:**

```{r, eval=TRUE}
# Summary by Stress Level AND college
student_data |> 
  group_by(Stress_Level, college) |> 
  summarize(
    n = n(),
    mean_hours = mean(Study_Hours_Per_Day),
    median_hours = median(Study_Hours_Per_Day),
    .groups = "drop"
  )
```

------------------------------------------------------------------------
  
### 6.3 Visualizing Grouped Data

**Bar chart of means:**

```{r, eval=summary_by_stresslevel}
ggplot(summary_by_major, aes(x = Stress_Level, y = mean_hours, fill = Stress_Level)) +
  geom_col() +
  geom_errorbar(aes(ymin = mean_hours - sd_hours, 
                    ymax = mean_hours + sd_hours),
                width = 0.2) +
  labs(
    title = "Mean Study Hours by Stress Level (±1 SD)",
    x = "Stress Level",
    y = "Mean Study Hours"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Grouped bar chart:**

```{r, eval=TRUE}
# Summary by stress level and college
summary_stress_college <- student_data |> 
  group_by(Stress_Level, college) |> 
  summarize(mean_hours = mean(Study_Hours_Per_Day), .groups = "drop")

ggplot(summary_stress_college, aes(x = Stress_Level, y = mean_hours, fill = college)) +
  geom_col(position = "dodge") +
  labs(
    title = "Mean Study Hours by Stress Level and College",
    x = "Stress Level",
    y = "Mean Study Hours",
    fill = "College"
  ) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()
```

------------------------------------------------------------------------

## 7. Correlation

### 7.1 Understanding Correlation

**Correlation** measures the strength and direction of the linear relationship between two numeric variables.

-   **r = 1**: Perfect positive correlation
-   **r = 0**: No linear correlation
-   **r = -1**: Perfect negative correlation

**Interpretation guidelines:**

| |r| | Strength |
|-----|----------|
| 0.00 - 0.19 | Very weak |
| 0.20 - 0.39 | Weak |
| 0.40 - 0.59 | Moderate |
| 0.60 - 0.79 | Strong |
| 0.80 - 1.00 | Very strong |

------------------------------------------------------------------------

### 7.2 Calculating Correlation

```{r, eval=TRUE}
# Pearson correlation (default)
cor(student_data$Study_Hours_Per_Day, student_data$GPA)
```

**Correlation test with p-value:**

```{r, eval=TRUE}
# Correlation test
cor_test <- cor.test(student_data$Study_Hours_Per_Day, student_data$GPA)
cor_test
```

**Interpretation:** There is a very strong positive correlation (r = `r round(cor_test$estimate, 3)`) between study hours and exam scores, p < 0.001.

------------------------------------------------------------------------

### 7.3 Correlation Matrices

When you have multiple numeric variables, create a correlation matrix:

```{r, eval=TRUE}
# Select numeric columns
numeric_vars <- student_data |> 
  select(Study_Hours_Per_Day, GPA)

# Correlation matrix
cor(numeric_vars)
```

**With more variables:**

```{r, eval=TRUE}
# Correlation matrix
numeric_vars <- student_data |> 
  select(Study_Hours_Per_Day, GPA, Sleep_Hours_Per_Day, Physical_Activity_Hours_Per_Day)

round(cor(numeric_vars), 3)
```

------------------------------------------------------------------------

### 7.4 Visualizing Correlations

**Scatter plot with correlation:**

```{r, eval=TRUE}
ggplot(student_data, aes(x = Study_Hours_Per_Day, y = GPA)) +
  geom_point(color = "steelblue", size = 3) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(
    title = paste("Study Hours vs GPA (r =", 
                  round(cor(student_data$Study_Hours_Per_Day, student_data$GPA), 2), ")"),
    x = "Study Hours",
    y = "GPA"
  ) +
  theme_minimal()
```

**Correlation heatmap:**

```{r, eval=TRUE}
# Create correlation matrix
cor_matrix <- cor(numeric_vars)

# Convert to long format for ggplot
cor_long <- cor_matrix |> 
  as.data.frame() |> 
  rownames_to_column("var1") |> 
  pivot_longer(-var1, names_to = "var2", values_to = "correlation")

# Heatmap
ggplot(cor_long, aes(x = var1, y = var2, fill = correlation)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(correlation, 2)), color = "black", size = 4) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       midpoint = 0, limits = c(-1, 1)) +
  labs(
    title = "Correlation Heatmap",
    x = "", y = "",
    fill = "Correlation"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

------------------------------------------------------------------------

#### Class Exercise: Correlation

1. Calculate the correlation between `GPA` and `Sleep_Hours_Per_day`.
2. Is the correlation statistically significant? (Use `cor.test()`)
3. Create a scatter plot showing this relationship.
4. What does this correlation tell us?

```{r}
### Your workspace
```

------------------------------------------------------------------------

## 8. Cross-Tabulations

Cross-tabulations (contingency tables) summarize the relationship between **categorical variables**.

### 8.1 Creating Frequency Tables

**Single variable:**

```{r, eval=TRUE}
# Using tidyverse
student_data |> 
  count(college)
```

**Two variables (cross-tabulation):**

```{r, eval=TRUE}
# Using tidyverse
student_data |> 
  count(college, Stress_Level) |> 
  pivot_wider(names_from = Stress_Level, values_from = n)
```

------------------------------------------------------------------------

### 8.2 Proportions and Percentages


```{r, eval=TRUE}
# Percentages by group
student_data |> 
  count(college, Stress_Level) |> 
  group_by(college) |> 
  mutate(
    percentage = n / sum(n) * 100
  )
```

------------------------------------------------------------------------

### 8.3 Visualizing Cross-Tabulations

**Stacked bar chart:**

```{r, eval=TRUE}
ggplot(student_data, aes(x = college, fill = Stress_Level)) +
  geom_bar() +
  labs(
    title = "Distribution of Stress Level by College",
    x = "College",
    y = "Count",
    fill = "Stress Level"
  ) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()
```

**Grouped bar chart:**

```{r, eval=TRUE}
ggplot(student_data, aes(x = college, fill = Stress_Level)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Distribution of Stress Level by College",
    x = "College",
    y = "Count",
    fill = "Stress Level"
  ) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()
```

**Proportional bar chart:**

```{r, eval=TRUE}
ggplot(student_data, aes(x = college, fill = Stress_Level)) +
  geom_bar(position = "fill") +
  labs(
    title = "Proportion of Stress Level by College",
    x = "College",
    y = "Proportion",
    fill = "Stress Level"
  ) +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

------------------------------------------------------------------------

**Three-way cross-tabulation:**

```{r, eval=TRUE}
# College by Stress Level by GPA
student_data |> 
  count(college, Stress_Level, GPA_Level) |> 
  pivot_wider(names_from = GPA_Level, values_from = n, values_fill = 0)
```

------------------------------------------------------------------------

#### Class Exercise: Cross-Tabulations

1. Create a cross-tabulation of `College` and `GPA_Level`.
2. What percentage of Medicine students have "High" GPA?
3. Create a proportional bar chart showing GPA levels by college
4. Which major has the highest proportion of `GPA_level` to `Stress_Level`?

```{r}
### Your workspace
```

------------------------------------------------------------------------

## Class Exercise 2

Using the `mtcars` dataset:

```{r, eval=TRUE}
data(mtcars)
head(mtcars)
```

1. **Central Tendency:** Calculate mean, median for `mpg` (miles per gallon).

2. **Spread:** Calculate standard deviation and IQR for `mpg`.

3. **Distribution:** Create a histogram and density plot of `mpg`.

4. **Outliers:** Use the IQR method to identify any outliers in `hp` (horsepower).

5. **Grouped Statistics:** Calculate mean `mpg` grouped by number of cylinders (`cyl`).

6. **Correlation:** Calculate the correlation between `mpg` and `wt` (weight). Create a scatter plot.

7. **Cross-tabulation:** Create a cross-tabulation of `cyl` and `gear`. Visualize with a bar chart.

```{r}
### Your workspace
```

------------------------------------------------------------------------

## Lecture 5 Cheat Sheet

| **Function/Concept** | **Description** | **Code Example** |
|----------------------|-----------------|------------------|
| `mean()` | Calculate arithmetic mean | `mean(x, na.rm = TRUE)` |
| `median()` | Calculate median (middle value) | `median(x)` |
| `sd()` | Calculate standard deviation | `sd(x)` |
| `var()` | Calculate variance | `var(x)` |
| `range()` | Get minimum and maximum | `range(x)` |
| `IQR()` | Calculate interquartile range | `IQR(x)` |
| `quantile()` | Calculate quantiles/percentiles | `quantile(x, 0.25)` |
| `summary()` | Get 5-number summary + mean | `summary(x)` |
| `table()` | Create frequency table | `table(df$category)` |
| `prop.table()` | Convert counts to proportions | `prop.table(table(x))` |
| `cor()` | Calculate correlation | `cor(x, y)` |
| `cor.test()` | Correlation test with p-value | `cor.test(x, y)` |
| `geom_histogram()` | Create histogram | `geom_histogram(binwidth = 5)` |
| `geom_density()` | Create density plot | `geom_density(fill = "blue")` |
| `geom_boxplot()` | Create boxplot | `geom_boxplot()` |
| `geom_tile()` | Create heatmap tiles | `geom_tile(aes(fill = value))` |
| `group_by() + summarize()` | Grouped statistics | `group_by(var) |> summarize(mean = mean(x))` |
| `count()` | Count observations | `count(var1, var2)` |
| `pivot_wider()` | Reshape long to wide | `pivot_wider(names_from, values_from)` |
| Z-score | Standardize values | `(x - mean(x)) / sd(x)` |
| IQR outliers | Values beyond 1.5×IQR | `Q1 - 1.5*IQR` or `Q3 + 1.5*IQR` |
